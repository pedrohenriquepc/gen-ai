{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Projeto: Generative AI - Avaliação de Modelo | Benchmark com Stanford Question Answering Dataset (SQuAD)**\n",
        "\n",
        "**Autor**: Pedro Henrique Pedroso da Cruz\n",
        "\n",
        "Este *notebook* contém exemplos de código para casos de validação de Modelos Gen AI através da abordagem de benchmarck, comparando com um dataset já preparado.\n",
        "\n",
        "*O código é um exemplo simples e direto para demonstrar uma das estratégias de avaliação de modelo, e não deve ser utilizado em ambiente de produção. Para boas práticas toda e qualquer Chave Key não utilizar estar Hard Code.*"
      ],
      "metadata": {
        "id": "gS5VpU2L2H1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Código"
      ],
      "metadata": {
        "id": "5uIogO0G3rO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração Ambiente\n",
        "\n",
        "Vamos escolher um modelo Hugging Face chamado \"distilbert-base-uncased-distilled-squad\".\n",
        "\n",
        "Mais informações acessar o link:\n",
        "\n",
        "https://huggingface.co/distilbert/distilbert-base-uncased-distilled-squad\n"
      ],
      "metadata": {
        "id": "Pw7bjjM32mXq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8haz8Aqu2CVr",
        "outputId": "dbcf2a33-db11-4024-9f67-fe975a386040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Instalar as bibliotecas necessárias\n",
        "!pip install transformers datasets\n",
        "\n",
        "# Importar as bibliotecas necessárias\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "\n",
        "# Carregar o modelo e o tokenizer da Hugging Face\n",
        "model_name = \"distilbert-base-uncased-distilled-squad\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# Configurar o pipeline de QA\n",
        "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando Dataset"
      ],
      "metadata": {
        "id": "ybwY88aQ3Bw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset SQuAD\n",
        "squad_dataset = load_dataset(\"squad\")"
      ],
      "metadata": {
        "id": "h79wSPAN3DtY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apresentar o Dataset"
      ],
      "metadata": {
        "id": "QyJ47UMJ_kDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para exibir algumas linhas do dataset\n",
        "def display_samples(num_samples=10):\n",
        "    samples = squad_dataset['validation'].select(range(num_samples))\n",
        "    for idx, sample in enumerate(samples):\n",
        "        print(f\"Index: {idx}\")\n",
        "        print(f\"Question: {sample['question']}\")\n",
        "        print(f\"Context: {sample['context'][:200]}...\")  # Limitar o contexto para melhor visualização\n",
        "        print(f\"Answer: {sample['answers']['text'][0]}\\n\")\n",
        "\n",
        "# Exibir 20 amostras do dataset\n",
        "display_samples(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAf9tdpC_miE",
        "outputId": "25a8c6aa-7f4c-4331-f9d3-0514760e6761"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 0\n",
            "Question: Which NFL team represented the AFC at Super Bowl 50?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: Denver Broncos\n",
            "\n",
            "Index: 1\n",
            "Question: Which NFL team represented the NFC at Super Bowl 50?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: Carolina Panthers\n",
            "\n",
            "Index: 2\n",
            "Question: Where did Super Bowl 50 take place?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: Santa Clara, California\n",
            "\n",
            "Index: 3\n",
            "Question: Which NFL team won Super Bowl 50?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: Denver Broncos\n",
            "\n",
            "Index: 4\n",
            "Question: What color was used to emphasize the 50th anniversary of the Super Bowl?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: gold\n",
            "\n",
            "Index: 5\n",
            "Question: What was the theme of Super Bowl 50?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: \"golden anniversary\"\n",
            "\n",
            "Index: 6\n",
            "Question: What day was the game played on?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: February 7, 2016\n",
            "\n",
            "Index: 7\n",
            "Question: What is the AFC short for?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: American Football Conference\n",
            "\n",
            "Index: 8\n",
            "Question: What was the theme of Super Bowl 50?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: \"golden anniversary\"\n",
            "\n",
            "Index: 9\n",
            "Question: What does AFC stand for?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: American Football Conference\n",
            "\n",
            "Index: 10\n",
            "Question: What day was the Super Bowl played on?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: February 7, 2016\n",
            "\n",
            "Index: 11\n",
            "Question: Who won Super Bowl 50?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: Denver Broncos\n",
            "\n",
            "Index: 12\n",
            "Question: What venue did Super Bowl 50 take place in?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: Levi's Stadium\n",
            "\n",
            "Index: 13\n",
            "Question: What city did Super Bowl 50 take place in?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: Santa Clara\n",
            "\n",
            "Index: 14\n",
            "Question: If Roman numerals were used, what would Super Bowl 50 have been called?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: Super Bowl L\n",
            "\n",
            "Index: 15\n",
            "Question: Super Bowl 50 decided the NFL champion for what season?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: 2015\n",
            "\n",
            "Index: 16\n",
            "Question: What year did the Denver Broncos secure a Super Bowl title for the third time?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: 2015\n",
            "\n",
            "Index: 17\n",
            "Question: What city did Super Bowl 50 take place in?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: Santa Clara\n",
            "\n",
            "Index: 18\n",
            "Question: What stadium did Super Bowl 50 take place in?\n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: Levi's Stadium\n",
            "\n",
            "Index: 19\n",
            "Question: What was the final score of Super Bowl 50? \n",
            "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated...\n",
            "Answer: 24–10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função para avaliação do modelo que compara as respostas geradas com as respostas corretas do SQuAD."
      ],
      "metadata": {
        "id": "IrneBCws3VSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para avaliar uma amostra\n",
        "def evaluate_sample(sample):\n",
        "    context = sample['context']\n",
        "    question = sample['question']\n",
        "    answer = sample['answers']['text'][0]\n",
        "\n",
        "    prediction = qa_pipeline({'context': context, 'question': question})['answer']\n",
        "\n",
        "    return question, prediction, answer"
      ],
      "metadata": {
        "id": "9CqnzwBP_zQD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método para calcular as métricas"
      ],
      "metadata": {
        "id": "OnfXJgdu3gQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para calcular métricas de avaliação\n",
        "def compute_metrics(predictions, references):\n",
        "    f1_scores = []\n",
        "    accuracies = []\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        pred_tokens = set(pred.split())\n",
        "        ref_tokens = set(ref.split())\n",
        "\n",
        "        # Calcular F1 Score\n",
        "        common_tokens = pred_tokens & ref_tokens\n",
        "        if len(common_tokens) == 0:\n",
        "            f1_scores.append(0)\n",
        "        else:\n",
        "            precision = len(common_tokens) / len(pred_tokens)\n",
        "            recall = len(common_tokens) / len(ref_tokens)\n",
        "            f1 = 2 * (precision * recall) / (precision + recall)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        # Calcular Exatidão\n",
        "        accuracies.append(int(pred == ref))\n",
        "\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "\n",
        "    return avg_f1, avg_accuracy"
      ],
      "metadata": {
        "id": "tmWON5as_4BO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise do resultados\n",
        "Validando um número especifico de questões"
      ],
      "metadata": {
        "id": "T7cIIPm93nqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para validar um número específico de questões\n",
        "def validate_questions(num_questions=10):\n",
        "    samples = squad_dataset['validation'].select(range(num_questions))\n",
        "    predictions = []\n",
        "    references = []\n",
        "    questions = []\n",
        "\n",
        "    for sample in samples:\n",
        "        question, pred, ref = evaluate_sample(sample)\n",
        "        questions.append(question)\n",
        "        predictions.append(pred)\n",
        "        references.append(ref)\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Generated Answer: {pred}\")\n",
        "        print(f\"Correct Answer: {ref}\\n\")\n",
        "\n",
        "    # Calcular e exibir as métricas\n",
        "    avg_f1, avg_accuracy = compute_metrics(predictions, references)\n",
        "    print(f\"F1 Score: {avg_f1:.2f}\")\n",
        "    print(f\"Accuracy: {avg_accuracy:.2f}\")\n",
        "\n",
        "# Validar um número específico de questões\n",
        "validate_questions(num_questions=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDtvjMUn9CH_",
        "outputId": "d4a957d6-dec2-4202-edfd-a97fe92567b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Which NFL team represented the AFC at Super Bowl 50?\n",
            "Generated Answer: Denver Broncos\n",
            "Correct Answer: Denver Broncos\n",
            "\n",
            "Question: Which NFL team represented the NFC at Super Bowl 50?\n",
            "Generated Answer: Carolina Panthers\n",
            "Correct Answer: Carolina Panthers\n",
            "\n",
            "Question: Where did Super Bowl 50 take place?\n",
            "Generated Answer: Levi's Stadium\n",
            "Correct Answer: Santa Clara, California\n",
            "\n",
            "Question: Which NFL team won Super Bowl 50?\n",
            "Generated Answer: Denver Broncos\n",
            "Correct Answer: Denver Broncos\n",
            "\n",
            "Question: What color was used to emphasize the 50th anniversary of the Super Bowl?\n",
            "Generated Answer: gold\n",
            "Correct Answer: gold\n",
            "\n",
            "Question: What was the theme of Super Bowl 50?\n",
            "Generated Answer: Arabic numerals\n",
            "Correct Answer: \"golden anniversary\"\n",
            "\n",
            "Question: What day was the game played on?\n",
            "Generated Answer: February 7, 2016\n",
            "Correct Answer: February 7, 2016\n",
            "\n",
            "Question: What is the AFC short for?\n",
            "Generated Answer: American Football Conference\n",
            "Correct Answer: American Football Conference\n",
            "\n",
            "Question: What was the theme of Super Bowl 50?\n",
            "Generated Answer: Arabic numerals\n",
            "Correct Answer: \"golden anniversary\"\n",
            "\n",
            "Question: What does AFC stand for?\n",
            "Generated Answer: American Football Conference\n",
            "Correct Answer: American Football Conference\n",
            "\n",
            "F1 Score: 0.70\n",
            "Accuracy: 0.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explicação das métricas"
      ],
      "metadata": {
        "id": "GeyBDYJKBCFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**F1 Score**\n",
        "\n",
        "O F1 Score é uma métrica de avaliação que considera tanto a precisão (precision) quanto a revocação (recall) de um modelo. Ele é aplicável para modelos de QA, e outros casos.\n",
        "\n",
        "\n",
        "*Precisão (Precision)*: A proporção de respostas corretas entre as respostas fornecidas pelo modelo.\n",
        "\n",
        "*Revocação (Recall)*: A proporção de respostas corretas identificadas pelo modelo entre todas as respostas corretas possíveis.\n",
        "Um **F1 Score de 0.70** indica que o modelo tem um equilíbrio razoável entre precisão e revocação. No contexto de QA, isso significa que,** em média, 70% das palavras ou frases geradas pelo modelo como respostas são corretas e relevantes**."
      ],
      "metadata": {
        "id": "2ntTBg9YBEUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy**\n",
        "\n",
        "A accuracy mede a proporção de respostas totalmente corretas em relação ao total de perguntas.\n",
        "\n",
        "Uma accuracy de **0.70 **significa que **70% das respostas fornecidas pelo modelo são exatamente iguais às respostas corretas do dataset SQuAD**."
      ],
      "metadata": {
        "id": "q2weA0vXBl0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretação do Resultado\n",
        "\n",
        "**F1 Score de 0.70**: Esse valor indica que o modelo é bastante competente em fornecer respostas que contêm os elementos corretos. No entanto, há espaço para melhoria, pois 30% das respostas podem estar faltando informações importantes ou incluindo informações irrelevantes.\n",
        "Vejamos um exemplo de resposta diferente:\n",
        "\n",
        "Question: What was the theme of Super Bowl 50?\n",
        "\n",
        "Generated Answer: Arabic numerals\n",
        "\n",
        "Correct Answer: \"golden anniversary\" *texto em itálico*\n",
        "\n",
        "**Accuracy de 0.70**: Este valor indica que o modelo fornece exatamente a resposta correta em 70% das perguntas. Isso é um bom resultado, especialmente considerando a dificuldade do SQuAD, que exige precisão e exatidão nas respostas.\n",
        "\n",
        "Aqui estamos validando apenas 10 questões, para o ideal seria validar o conjunto completo, existindo ainda a possibilidade de adicionar suas questões e respostas para o case de negócio."
      ],
      "metadata": {
        "id": "Xu7hmietB3Gq"
      }
    }
  ]
}