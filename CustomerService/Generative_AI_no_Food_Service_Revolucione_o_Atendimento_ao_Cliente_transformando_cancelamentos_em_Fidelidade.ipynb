{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Projeto: Generative AI no Food Service: Revolucione o Atendimento ao Cliente transformando cancelamentos em Fidelidade**\n",
        "\n",
        "**Autor**: Pedro Henrique Pedroso da Cruz\n",
        "\n",
        "Este *notebook* contém exemplos de código para casos de Usos de Food Service com Generative AI, utilizando modelo Open AI.\n",
        "\n",
        "O notebook fornece exemplos simples sobre casos de uso Customer Service, auxiliando funcionários como responder possiveis cancelamentos de pedidos de compra, e até mesmo sugerindo respostas para informar que o item solicitado não está mais disponivel, tentando desenvolver uma ótima experiência de compra para o cliente.\n",
        "\n",
        "O código a seguir não é apropriado para um ambiente de produção, sendo meramente um exemplo de uso de Gen AI."
      ],
      "metadata": {
        "id": "qUTnUpMMmLk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Casos de Uso\n",
        "Assistente para:\n",
        "\n",
        "**Informando que o item solicitado não está disponível**: ao utilizar Assistente gerar respostas a clientes, onde o item solicitado não está mais disponível no estoque.\n",
        "\n",
        "**Revertendo Cancelamento de Compras**: Assistente para gerar respostas convertendo um pedido de cancelamento de compra por algum motivo para uma fidelização.\n",
        "\n"
      ],
      "metadata": {
        "id": "JIQHYbi6o8To"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup Ambiente**"
      ],
      "metadata": {
        "id": "kmIpm72mEBQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando Pacotes\n"
      ],
      "metadata": {
        "id": "oyTie1mVmLk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2023-07-21T15:06:34.660555Z",
          "iopub.execute_input": "2023-07-21T15:06:34.66125Z",
          "iopub.status.idle": "2023-07-21T15:11:19.380417Z",
          "shell.execute_reply.started": "2023-07-21T15:06:34.661212Z",
          "shell.execute_reply": "2023-07-21T15:11:19.378202Z"
        },
        "trusted": true,
        "id": "OYhhv247mLk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplo Código\n",
        "\n",
        "# Caso de Uso I\n",
        "\n",
        "#Assistente para gerar resposta: Informando item não disponivel"
      ],
      "metadata": {
        "id": "jZKIRarLmLk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Configurar a API Key\n",
        "openai.api_key = 'inserir-sua-chave-api-openai-aqui'\n",
        "\n",
        "# Dados de exemplo\n",
        "menu = {\n",
        "    \"lasanha\": {\"preco_venda\": 20.0, \"preco_custo\": 10.0, \"lucro_medio\": 10.0, \"estoque\": 0, \"ingredientes\": [\"massa\", \"molho\", \"queijo\"]},\n",
        "    \"espaguete\": {\"preco_venda\": 15.0, \"preco_custo\": 7.0, \"lucro_medio\": 8.0, \"estoque\": 5, \"ingredientes\": [\"massa\", \"molho\"]},\n",
        "    \"ravioli\": {\"preco_venda\": 18.0, \"preco_custo\": 9.0, \"lucro_medio\": 9.0, \"estoque\": 3, \"ingredientes\": [\"massa\", \"queijo\"]},\n",
        "    \"fettuccine\": {\"preco_venda\": 17.0, \"preco_custo\": 8.0, \"lucro_medio\": 9.0, \"estoque\": 4, \"ingredientes\": [\"massa\", \"molho\", \"queijo\"]}\n",
        "}\n",
        "\n",
        "pedido = \"lasanha\"\n",
        "ticket_medio = 16.0\n",
        "\n",
        "def sugerir_alternativa(pedido, menu):\n",
        "    \"\"\"\n",
        "    Sugere uma alternativa ao pedido que está fora de estoque, baseada no lucro médio.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pedido : str\n",
        "        Nome do prato solicitado pelo cliente que está fora de estoque.\n",
        "    menu : dict\n",
        "        Dicionário contendo informações sobre os pratos, incluindo preço de venda, custo, lucro médio, estoque e ingredientes.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    alternativa_sugerida : str\n",
        "        Nome do prato alternativo sugerido.\n",
        "    info_alternativa : dict\n",
        "        Dicionário com as informações do prato alternativo sugerido.\n",
        "    \"\"\"\n",
        "    alternativas = {prato: info for prato, info in menu.items() if prato != pedido and info[\"estoque\"] > 0}\n",
        "    alternativa_sugerida = max(alternativas, key=lambda x: alternativas[x][\"lucro_medio\"])\n",
        "    return alternativa_sugerida, alternativas[alternativa_sugerida]\n",
        "\n",
        "def gerar_resposta_cliente(pedido, alternativa, info_alternativa):\n",
        "    \"\"\"\n",
        "    Gera uma resposta para o cliente usando a API da OpenAI, sugerindo um prato alternativo e oferecendo um desconto.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pedido : str\n",
        "        Nome do prato solicitado pelo cliente que está fora de estoque.\n",
        "    alternativa : str\n",
        "        Nome do prato alternativo sugerido.\n",
        "    info_alternativa : dict\n",
        "        Dicionário com as informações do prato alternativo sugerido.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Resposta gerada pela API da OpenAI, com uma sugestão de prato alternativo e um pedido de desculpas.\n",
        "    \"\"\"\n",
        "    prompt = f\"Cliente pediu {pedido}, mas não está disponível. Sugira {alternativa} que custa {info_alternativa['preco_venda']}. Adicione um pedido de desculpas e um desconto para a próxima compra.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Você é um assistente que ajuda clientes em um restaurante.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "\n",
        "# Exemplo de uso\n",
        "alternativa, info_alternativa = sugerir_alternativa(pedido, menu)\n",
        "resposta_cliente = gerar_resposta_cliente(pedido, alternativa, info_alternativa)\n",
        "print(resposta_cliente)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ain--qk7NNR8",
        "outputId": "19112cc3-d9f2-4fcd-ba4e-c5b0efd3c719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Desculpe pela falta de lasanha no momento. Posso sugerir o ravioli, que custa R$18,00. Como forma de compensação pela indisponibilidade do prato desejado, oferecemos um desconto de 10% em sua próxima compra. Espero que goste da sugestão! Posso incluir o ravioli no seu pedido?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplo Código\n",
        "\n",
        "# Caso de Uso II\n",
        "\n",
        "#Assistente para gerar resposta: Revertendo um cancelamento de compra em fidelidade"
      ],
      "metadata": {
        "id": "iaMvprv0LYeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Configurar a API Key\n",
        "openai.api_key = 'inserir-sua-chave-api-openai-aqui'\n",
        "\n",
        "def gerar_resposta_cancelamento(pedido, motivo):\n",
        "    \"\"\"\n",
        "    Gera uma resposta de cancelamento de pedido usando a API da OpenAI, oferecendo um item adicional e um cupom de desconto.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pedido : str\n",
        "        Nome do prato que o cliente deseja cancelar.\n",
        "    motivo : str\n",
        "        Motivo pelo qual o cliente deseja cancelar o pedido.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Resposta gerada pela API da OpenAI, oferecendo um item adicional e um cupom de desconto de 10% para a próxima compra.\n",
        "    \"\"\"\n",
        "    prompt = f\"O cliente quer cancelar o pedido de {pedido} devido a {motivo}. Gere uma resposta educada oferecendo um item adicional caso ele não cancele e um cupom de desconto de 10% para a próxima compra.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Você é um assistente que ajuda clientes em um restaurante.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "\n",
        "# Exemplo de uso\n",
        "pedido = \"lasanha\"\n",
        "motivo = \"tempo de espera\"\n",
        "resposta_cancelamento = gerar_resposta_cancelamento(pedido, motivo)\n",
        "print(resposta_cancelamento)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUZHilhpNpSm",
        "outputId": "09f04a2a-8061-4eff-e933-922bbe3d2f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peço desculpas pelo tempo de espera no pedido de lasanha. Se preferir manter o pedido, gostaríamos de oferecer um item adicional como cortesia. Além disso, para compensar o transtorno, você receberá um cupom de desconto de 10% para utilizar em sua próxima compra. Por favor, nos informe sua decisão. Caso deseje cancelar o pedido de lasanha, podemos providenciar imediatamente. Obrigado pela compreensão.\n"
          ]
        }
      ]
    }
  ]
}